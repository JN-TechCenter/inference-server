import argparse
import ast
import math
import os
import sys
import time
import cv2
import numpy as np
import yaml
from datetime import datetime

import mindspore as ms
from mindspore import Tensor, nn

from mindyolo.data import COCO80_TO_COCO91_CLASS
from mindyolo.models import create_model
from mindyolo.utils import logger
from mindyolo.utils.config import parse_args
from mindyolo.utils.metrics import non_max_suppression, scale_coords, xyxy2xywh, process_mask_upsample, scale_image
from mindyolo.utils.utils import draw_result, set_seed
def get_parser_infer(parents=None):
    parser = argparse.ArgumentParser(description="æ¨ç†ä»»åŠ¡å‚æ•°", parents=[parents] if parents else [])
    
    # åœ¨ç°æœ‰å‚æ•°åŸºç¡€ä¸Šæ·»åŠ dataå‚æ•°
    parser.add_argument('--data', type=str, default='configs/yolov5/yolov5s.yaml', 
                       help='æ•°æ®é›†é…ç½®æ–‡ä»¶è·¯å¾„')
    
    parser.add_argument("--task", type=str, default="detect", choices=["detect", "segment"],
                        help="æ¨ç†ä»»åŠ¡ç±»å‹ï¼šdetect=æ£€æµ‹ï¼Œsegment=åˆ†å‰²")

    parser.add_argument("--device_target", type=str, default="Ascend",
                        help="è®¾å¤‡é€‰æ‹©ï¼šAscendã€GPU æˆ– CPU")

    parser.add_argument("--ms_mode", type=int, default=0,
                        help="MindSporeæ‰§è¡Œæ¨¡å¼ï¼š0=å›¾æ¨¡å¼ï¼Œ1=åŠ¨æ€å›¾ï¼ˆpynativeï¼‰")

    parser.add_argument("--ms_amp_level", type=str, default="O0",
                        help="è‡ªåŠ¨æ··åˆç²¾åº¦ç­‰çº§ï¼šO0=ä¸ä½¿ç”¨ï¼ŒO1/O2=æ··åˆç²¾åº¦ç­‰çº§")

    parser.add_argument("--ms_enable_graph_kernel", type=ast.literal_eval, default=False,
                        help="æ˜¯å¦å¯ç”¨å›¾ç®—èåˆï¼ˆGraph Kernelï¼‰")

    parser.add_argument("--precision_mode", type=str, default=None,
                        help="ç²¾åº¦æ¨¡å¼è®¾ç½®ï¼ˆç”¨äºAscendè®¾å¤‡ï¼‰")

    parser.add_argument("--weight", type=str, default="yolov7_300.ckpt",
                        help="æƒé‡æ–‡ä»¶è·¯å¾„ï¼ˆmodel.ckptï¼‰")

    parser.add_argument("--img_size", type=int, default=640,
                        help="è¾“å…¥å›¾ç‰‡å°ºå¯¸ï¼ˆæ­£æ–¹å½¢è¾¹é•¿ï¼Œå•ä½åƒç´ ï¼‰")

    parser.add_argument("--interpolation", type=str, default='default', choices=['default', 'nearest'],
                        help="æ’å€¼æ–¹æ³•: 'default' (é»˜è®¤) æˆ– 'nearest' (æœ€è¿‘é‚»)")

    parser.add_argument("--single_cls", type=ast.literal_eval, default=False,
                        help="æ˜¯å¦å°†å¤šç±»åˆ«æ•°æ®è§†ä¸ºå•ç±»åˆ«")

    parser.add_argument("--exec_nms", type=ast.literal_eval, default=True,
                        help="æ˜¯å¦æ‰§è¡Œéæå¤§å€¼æŠ‘åˆ¶ï¼ˆNMSï¼‰")

    parser.add_argument("--nms_time_limit", type=float, default=60.0,
                        help="NMSçš„æ—¶é—´é™åˆ¶ï¼ˆç§’ï¼‰")

    parser.add_argument("--conf_thres", type=float, default=0.25,
                        help="ç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆä½äºè¯¥å€¼çš„æ¡†ä¼šè¢«è¿‡æ»¤ï¼‰")

    parser.add_argument("--iou_thres", type=float, default=0.65,
                        help="NMSçš„IOUé˜ˆå€¼")

    parser.add_argument("--conf_free", type=ast.literal_eval, default=False,
                        help="æ˜¯å¦ä»é¢„æµ‹ç»“æœä¸­ç‹¬ç«‹å‰¥ç¦»ç½®ä¿¡åº¦å€¼")

    parser.add_argument("--seed", type=int, default=2,
                        help="éšæœºç§å­ï¼ˆç”¨äºç»“æœå¤ç°ï¼‰")

    parser.add_argument("--log_level", type=str, default="INFO",
                        help="æ—¥å¿—ç­‰çº§ï¼Œå¦‚INFOã€DEBUGç­‰")

    parser.add_argument("--save_dir", type=str, default="./runs_infer",
                        help="æ¨ç†ç»“æœä¿å­˜ç›®å½•")

    parser.add_argument("--image_path", type=str,
                        help="è¾“å…¥å›¾ç‰‡è·¯å¾„")

    parser.add_argument("--save_result", type=ast.literal_eval, default=False,
                        help="æ˜¯å¦ä¿å­˜æ¨ç†ç»“æœ")

    parser.add_argument("--log_file", type=str, default="infer.log",
                        help="æ—¥å¿—æ–‡ä»¶ä¿å­˜è·¯å¾„")

    return parser



# åœ¨set_default_inferå‡½æ•°ä¸­ç¦ç”¨æ—¥å¿—æ–‡ä»¶
def set_default_infer(args):
    # è®¾ç½® MindSpore æ‰§è¡Œä¸Šä¸‹æ–‡æ¨¡å¼
    ms.set_context(mode=args.ms_mode)
    
    # è®¾ç½®æœ€å¤§é€’å½’æ·±åº¦
    ms.set_recursion_limit(2000)

    # å¦‚æœè®¾ç½®äº†ç²¾åº¦æ¨¡å¼ï¼Œåˆ™é…ç½®ç²¾åº¦ï¼ˆç”¨äº Ascendï¼‰
    if args.precision_mode is not None:
        ms.device_context.ascend.op_precision.precision_mode(args.precision_mode)

    # å¦‚æœä½¿ç”¨å›¾æ¨¡å¼ï¼Œåˆ™è®¾ç½® JIT ç¼–è¯‘ç­‰çº§ä¸º O2
    if args.ms_mode == 0:
        ms.set_context(jit_config={"jit_level": "O2"})

    # æ™ºèƒ½è®¾å¤‡é€‰æ‹©ï¼šä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡ï¼Œç„¶åè‡ªåŠ¨æ£€æµ‹
    device_target = os.getenv('DEVICE_TARGET', args.device_target)
    
    # è‡ªåŠ¨æ£€æµ‹GPUå¯ç”¨æ€§
    if device_target == "Ascend" or device_target == "GPU":
        try:
            # å°è¯•è®¾ç½®GPU/Ascendæ¨¡å¼è¿›è¡Œæµ‹è¯•
            if device_target == "GPU":
                # æ£€æµ‹NVIDIA GPU
                try:
                    import pynvml
                    pynvml.nvmlInit()
                    gpu_count = pynvml.nvmlDeviceGetCount()
                    if gpu_count > 0:
                        ms.set_context(device_target="GPU", device_id=int(os.getenv("DEVICE_ID", 0)))
                        logger.info(f"âœ… æˆåŠŸå¯ç”¨GPUæ¨¡å¼ï¼Œæ£€æµ‹åˆ°{gpu_count}ä¸ªGPUè®¾å¤‡")
                    else:
                        raise RuntimeError("æœªæ£€æµ‹åˆ°GPUè®¾å¤‡")
                except (ImportError, Exception) as e:
                    logger.warning(f"GPUæ£€æµ‹å¤±è´¥: {e}ï¼Œé™çº§åˆ°CPUæ¨¡å¼")
                    device_target = "CPU"
                    ms.set_context(device_target="CPU")
            else:
                # Ascendè®¾å¤‡å¤„ç†
                ms.set_context(device_target="Ascend")
                ms.set_device("Ascend", int(os.getenv("DEVICE_ID", 0)))
                logger.info("âœ… æˆåŠŸå¯ç”¨Ascendæ¨¡å¼")
        except Exception as e:
            logger.warning(f"è®¾å¤‡è®¾ç½®å¤±è´¥: {e}ï¼Œé™çº§åˆ°CPUæ¨¡å¼")
            device_target = "CPU"
            ms.set_context(device_target="CPU")
    else:
        # æ˜¾å¼CPUæ¨¡å¼
        ms.set_context(device_target="CPU")
        logger.info("ğŸ–¥ï¸ ä½¿ç”¨CPUæ¨¡å¼")

    # è®¾ç½® rank å’Œ rank_sizeï¼ˆç”¨äºå¤šå¡è®­ç»ƒï¼Œè¿™é‡Œé»˜è®¤å•å¡ï¼‰xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxpppppppppppppppppppppppppppppppppp
    args.rank, args.rank_size = 0, 1

    # æ ¹æ®æ˜¯å¦ä¸ºå•ç±»åˆ«ä»»åŠ¡ï¼Œè®¾ç½®ç±»åˆ«æ•°å’Œç±»åˆ«åç§°
    args.data.nc = 1 if args.single_cls else int(args.data.nc)  # ç±»åˆ«æ•°
    args.data.names = ["item"] if args.single_cls and len(args.names) != 1 else args.data.names  # ç±»åˆ«åç§°

    # æ ¡éªŒç±»åˆ«åç§°å’Œç±»åˆ«æ•°é‡æ˜¯å¦ä¸€è‡´
    assert len(args.data.names) == args.data.nc, "%g names found for nc=%g dataset in %s" % (
        len(args.data.names),
        args.data.nc,
        args.config,
    )

    # è®¾ç½®ä¿å­˜ç›®å½•åï¼Œæ ¼å¼ä¸ºï¼š./runs_infer/YYYY.MM.DD-HH:MM:SS
    platform = sys.platform
    if platform == "win32":
        args.save_dir = os.path.join(args.save_dir, datetime.now().strftime("%Y.%m.%d-%H.%M.%S"))
    else:
        args.save_dir = os.path.join(args.save_dir, datetime.now().strftime("%Y.%m.%d-%H:%M:%S"))

    # åˆ›å»ºä¿å­˜ç›®å½•
    os.makedirs(args.save_dir, exist_ok=True)

    # å¦‚æœæ˜¯ä¸»è¿›ç¨‹ï¼Œä¿å­˜å½“å‰å‚æ•°é…ç½®ä¸º cfg.yaml æ–‡ä»¶
    if args.rank % args.rank_size == 0:
        with open(os.path.join(args.save_dir, "cfg.yaml"), "w") as f:
            yaml.dump(vars(args), f, sort_keys=False)

    # è®¾ç½®æ—¥å¿—ç³»ç»Ÿï¼šåˆå§‹åŒ–åŸºæœ¬æ—¥å¿—è®°å½•å™¨
    logger.setup_logging(logger_name="MindYOLO", log_level="INFO", rank_id=args.rank, device_per_servers=args.rank_size)

    # è®¾ç½®æ—¥å¿—æ–‡ä»¶ä¿å­˜è·¯å¾„
    # æ³¨é‡Šæ‰æ—¥å¿—æ–‡ä»¶è®¾ç½®
    # logger.setup_logging_file(log_dir=os.path.join(args.save_dir, "logs"))
def detect(
    network: nn.Cell,               # MindSporeæ¨¡å‹
    img: np.ndarray,                # è¾“å…¥å›¾åƒï¼ˆBGRæ ¼å¼ï¼‰
    conf_thres: float = 0.25,       # ç½®ä¿¡åº¦é˜ˆå€¼
    iou_thres: float = 0.65,        # NMSçš„IoUé˜ˆå€¼
    conf_free: bool = False,        # æ˜¯å¦ä¸åŒ…å«ç½®ä¿¡åº¦ï¼ˆç”¨äºç‰¹æ®Šæ¨¡å‹ï¼‰
    exec_nms: bool = True,          # æ˜¯å¦æ‰§è¡ŒNMS
    nms_time_limit: float = 60.0,   # NMSæ—¶é—´é™åˆ¶
    img_size: int = 640,            # æ¨ç†å›¾åƒå°ºå¯¸
    stride: int = 32,               # æ¨¡å‹ä¸‹é‡‡æ ·æ­¥é•¿
    num_class: int = 80,            # ç±»åˆ«æ•°
    is_coco_dataset: bool = True,   # æ˜¯å¦ä½¿ç”¨COCOæ•°æ®é›†ï¼ˆç”¨äºæ ‡ç­¾æ˜ å°„ï¼‰
):
    # å›¾åƒç¼©æ”¾å¤„ç†
    h_ori, w_ori = img.shape[:2]  # åŸå›¾å°ºå¯¸
    r = img_size / max(h_ori, w_ori)  # ç¼©æ”¾æ¯”ä¾‹
    if r != 1:  # è‹¥éœ€ç¼©æ”¾å›¾åƒ
        interp = cv2.INTER_AREA if r < 1 else cv2.INTER_LINEAR
        img = cv2.resize(img, (int(w_ori * r), int(h_ori * r)), interpolation=interp)
    h, w = img.shape[:2]
    
    # å¦‚æœå°ºå¯¸ä»ä¸è¶³ï¼Œå¡«å……è¾¹ç•Œåˆ°ç¬¦åˆæ­¥é•¿
    if h < img_size or w < img_size:
        new_h, new_w = math.ceil(h / stride) * stride, math.ceil(w / stride) * stride
        dh, dw = (new_h - h) / 2, (new_w - w) / 2
        top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))
        left, right = int(round(dw - 0.1)), int(round(dw + 0.1))
        img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=(114, 114, 114))  # å¡«å……ç°è‰²

    # å›¾åƒæ ¼å¼è½¬æ¢å¹¶å½’ä¸€åŒ–
    logger.debug(f'[é¢„å¤„ç†] è½¬æ¢å‰å¸§ä¿¡æ¯ å½¢çŠ¶ï¼š{img.shape} é€šé“é¡ºåºï¼šBGR')
    img = img[:, :, ::-1].transpose(2, 0, 1) / 255.0  # BGR->RGBå¹¶è½¬ä¸ºCHWï¼Œå½’ä¸€åŒ–
    logger.debug(f'[é¢„å¤„ç†] è½¬æ¢åå¸§å½¢çŠ¶ï¼š{img.shape} æ•°å€¼èŒƒå›´ï¼š[{img.min():.3f}, {img.max():.3f}]')
    imgs_tensor = Tensor(img[None], ms.float32)  # å¢åŠ batchç»´åº¦
    logger.debug(f'[å¼ é‡è½¬æ¢] è¾“å…¥å¼ é‡å½¢çŠ¶ï¼š{imgs_tensor.shape} æ•°æ®ç±»å‹ï¼š{imgs_tensor.dtype}')

    # æ¨ç†é˜¶æ®µ
    _t = time.time()
    out, _ = network(imgs_tensor)
    out = out[-1] if isinstance(out, (tuple, list)) else out  # å–æœ€ç»ˆè¾“å‡º
    infer_times = time.time() - _t

    # æ‰§è¡ŒNMSå»é‡
    t = time.time()
    out = out.asnumpy()
    out = non_max_suppression(
        out, conf_thres=conf_thres, iou_thres=iou_thres, conf_free=conf_free,
        multi_label=True, time_limit=nms_time_limit, need_nms=exec_nms
    )
    nms_times = time.time() - t

    # å¤„ç†æ¨ç†ç»“æœ
    logger.info(f'[æ¨ç†è¾“å‡º] åŸå§‹æ£€æµ‹æ¡†æ•°é‡ï¼š{sum(len(p) for p in out)} æœ‰æ•ˆå¸§ï¼š{len([p for p in out if len(p)>0])}/{len(out)}')
    result_dict = {"category_id": [], "bbox": [], "score": []}
    total_category_ids, total_bboxes, total_scores = [], [], []
    for si, pred in enumerate(out):
        logger.debug(f'å¸§{si+1} åˆå§‹æ£€æµ‹æ¡†ï¼š{len(pred)}ä¸ª')
        if len(pred) == 0:
            logger.debug(f'å¸§{si+1} æ— æœ‰æ•ˆæ£€æµ‹ç»“æœ')
            continue
        predn = np.copy(pred)
        scale_coords(img.shape[1:], predn[:, :4], (h_ori, w_ori))  # å°†åæ ‡ç¼©æ”¾å›åŸå›¾å°ºå¯¸

        box = xyxy2xywh(predn[:, :4])  # è½¬ä¸ºxywhæ ¼å¼
        box[:, :2] -= box[:, 2:] / 2  # ä¸­å¿ƒåæ ‡è½¬å·¦ä¸Šè§’

        # æå–ç»“æœä¿¡æ¯
        category_ids, bboxes, scores = [], [], []
        for p, b in zip(pred.tolist(), box.tolist()):
            category_ids.append(COCO80_TO_COCO91_CLASS[int(p[5])] if is_coco_dataset else int(p[5]))
            bboxes.append([round(x, 3) for x in b])
            scores.append(round(p[4], 5))

        total_category_ids.extend(category_ids)
        total_bboxes.extend(bboxes)
        total_scores.extend(scores)

    # å†™å…¥ç»“æœå­—å…¸
    result_dict["category_id"].extend(total_category_ids)
    result_dict["bbox"].extend(total_bboxes)
    result_dict["score"].extend(total_scores)

    # æ‰“å°æ—¥å¿—ä¿¡æ¯
    t = tuple(x * 1e3 for x in (infer_times, nms_times, infer_times + nms_times)) + (img_size, img_size, 1)
    logger.info(f"Predict result is: {result_dict}")
    logger.info(f"Speed: %.1f/%.1f/%.1f ms inference/NMS/total per %gx%g image at batch-size %g;" % t)
    logger.info(f"Detect a image success.")

    # åœ¨è¿”å›ç»“æœå‰æ·»åŠ æ ¡éªŒ
    if len(total_category_ids) == 0:
        logger.warning("æœªæ£€æµ‹åˆ°æœ‰æ•ˆç›®æ ‡ï¼Œè¯·æ£€æŸ¥ï¼š")
        logger.warning(f"- ç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆå½“å‰å€¼ï¼š{conf_thres}ï¼‰")
        logger.warning("- æ¨¡å‹è¾“å…¥å°ºå¯¸æ˜¯å¦åˆé€‚")
        logger.warning("- æƒé‡æ–‡ä»¶æ˜¯å¦ä¸æ¨¡å‹åŒ¹é…")
    else:
        logger.info(f"æ£€æµ‹åˆ°{len(total_category_ids)}ä¸ªç›®æ ‡ï¼Œç±»åˆ«åˆ†å¸ƒï¼š{np.bincount(total_category_ids)}")
    
    return result_dict


def segment(
    network: nn.Cell,
    img: np.ndarray,
    conf_thres: float = 0.25,
    iou_thres: float = 0.65,
    conf_free: bool = False,
    nms_time_limit: float = 60.0,
    img_size: int = 640,
    stride: int = 32,
    num_class: int = 80,
    is_coco_dataset: bool = True,
):
    # å›¾åƒç¼©æ”¾
    h_ori, w_ori = img.shape[:2]
    r = img_size / max(h_ori, w_ori)
    if r != 1:
        interp = cv2.INTER_AREA if r < 1 else cv2.INTER_LINEAR
        img = cv2.resize(img, (int(w_ori * r), int(h_ori * r)), interpolation=interp)
    h, w = img.shape[:2]
    if h < img_size or w < img_size:
        new_h, new_w = math.ceil(h / stride) * stride, math.ceil(w / stride) * stride
        dh, dw = (new_h - h) / 2, (new_w - w) / 2
        top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))
        left, right = int(round(dw - 0.1)), int(round(dw + 0.1))
        img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=(114, 114, 114))

    # æ ¼å¼è½¬æ¢ä¸å½’ä¸€åŒ–
    img = img[:, :, ::-1].transpose(2, 0, 1) / 255.0
    imgs_tensor = Tensor(img[None], ms.float32)

    # æ¨ç†é˜¶æ®µ
    _t = time.time()
    out, (_, _, prototypes) = network(imgs_tensor)  # åŒæ—¶è¾“å‡ºmaskåŸå‹
    infer_times = time.time() - _t

    # NMSå¤„ç†
    t = time.time()
    _c = num_class + 4 if conf_free else num_class + 5
    out = out.asnumpy()
    bboxes, mask_coefficient = out[:, :, :_c], out[:, :, _c:]
    out = non_max_suppression(
        bboxes, mask_coefficient,
        conf_thres=conf_thres, iou_thres=iou_thres,
        conf_free=conf_free, multi_label=True,
        time_limit=nms_time_limit
    )
    nms_times = time.time() - t

    prototypes = prototypes.asnumpy()

    result_dict = {"category_id": [], "bbox": [], "score": [], "segmentation": []}
    total_category_ids, total_bboxes, total_scores, total_seg = [], [], [], []

    # éå†æ¯ä¸ªå›¾åƒçš„ç»“æœ
    for si, (pred, proto) in enumerate(zip(out, prototypes)):
        if len(pred) == 0:
            continue

        # ç”Ÿæˆæ©ç 
        pred_masks = process_mask_upsample(proto, pred[:, 6:], pred[:, :4], shape=imgs_tensor[si].shape[1:])
        pred_masks = pred_masks.astype(np.float32)
        pred_masks = scale_image((pred_masks.transpose(1, 2, 0)), (h_ori, w_ori))

        # åæ ‡ç¼©æ”¾å›åŸå›¾
        predn = np.copy(pred)
        scale_coords(img.shape[1:], predn[:, :4], (h_ori, w_ori))
        box = xyxy2xywh(predn[:, :4])
        box[:, :2] -= box[:, 2:] / 2

        category_ids, bboxes, scores, segs = [], [], [], []
        for ii, (p, b) in enumerate(zip(pred.tolist(), box.tolist())):
            category_ids.append(COCO80_TO_COCO91_CLASS[int(p[5])] if is_coco_dataset else int(p[5]))
            bboxes.append([round(x, 3) for x in b])
            scores.append(round(p[4], 5))
            segs.append(pred_masks[:, :, ii])  # æ©ç æ·»åŠ 

        total_category_ids.extend(category_ids)
        total_bboxes.extend(bboxes)
        total_scores.extend(scores)
        total_seg.extend(segs)

    # å†™å…¥ç»“æœå­—å…¸
    result_dict["category_id"].extend(total_category_ids)
    result_dict["bbox"].extend(total_bboxes)
    result_dict["score"].extend(total_scores)
    result_dict["segmentation"].extend(total_seg)

    # è¾“å‡ºæ—¥å¿—
    t = tuple(x * 1e3 for x in (infer_times, nms_times, infer_times + nms_times)) + (img_size, img_size, 1)
    logger.info(f"Predict result is:")
    for k, v in result_dict.items():
        if k == "segmentation":
            logger.info(f"{k} shape: {v[0].shape}")
        else:
            logger.info(f"{k}: {v}")
    logger.info(f"Speed: %.1f/%.1f/%.1f ms inference/NMS/total per %gx%g image at batch-size %g;" % t)
    logger.info(f"Detect a image success.")

    return result_dict
def infer(args, frame=None):
    # å¢å¼ºå‹è¾“å…¥éªŒè¯ï¼ˆæ·»åŠ å›¾åƒæ ¼å¼æ£€æŸ¥ï¼‰
    logger.debug(f"[è¾“å…¥éªŒè¯] åŸå§‹å¸§ç±»å‹ï¼š{type(args.image_path)} å½¢çŠ¶ï¼š{args.image_path.shape if hasattr(args.image_path, 'shape') else 'N/A'}")
    if frame is not None:
        img = frame.copy()
        logger.debug(f'[è¾“å…¥éªŒè¯] å†…å­˜å¸§ä¿¡æ¯ ç±»å‹ï¼š{img.dtype} å½¢çŠ¶ï¼š{img.shape} å‡å€¼ï¼š{np.mean(img):.2f}')
    elif isinstance(args.image_path, np.ndarray):
        if args.image_path.dtype != np.uint8 or args.image_path.ndim != 3:
            raise ValueError("è§†é¢‘å¸§æ ¼å¼å¿…é¡»ä¸ºuint8ç±»å‹çš„3ç»´numpyæ•°ç»„ï¼ˆHWC-BGRæ ¼å¼ï¼‰")
        img = args.image_path.copy()  # ä¿æŒåŸå§‹å¸§ä¸å˜
        logger.debug(f'[è¾“å…¥éªŒè¯] æ‹·è´åå¸§ä¿¡æ¯ ç±»å‹ï¼š{img.dtype} å½¢çŠ¶ï¼š{img.shape} å‡å€¼ï¼š{np.mean(img):.2f}')
    elif isinstance(args.image_path, str) and os.path.isfile(args.image_path):
        img = cv2.imread(args.image_path)
        if img is None:
            raise ValueError(f"æ— æ³•è¯»å–å›¾åƒæ–‡ä»¶ï¼š{args.image_path}")
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„è¾“å…¥ç±»å‹ï¼š{type(args.image_path)}ï¼Œæ”¯æŒç±»å‹ï¼šnumpyæ•°ç»„æˆ–å›¾ç‰‡è·¯å¾„")

    # ç§»é™¤å†—ä½™çš„å›¾ç‰‡åŠ è½½ä»£ç å—
    # if isinstance(args.image_path, str) and os.path.isfile(args.image_path):
    #     import cv2
    #     img = cv2.imread(args.image_path)  # è¯»å–å›¾åƒ
    # else:
    #     raise ValueError("Detect: input image file not available.") 

    # æ·»åŠ è¾“å…¥æ ¼å¼æ—¥å¿—è®°å½•
    logger.debug(f"è¾“å…¥å›¾åƒç±»å‹ï¼š{type(img)}ï¼Œå½¢çŠ¶ï¼š{img.shape}ï¼Œæ•°æ®ç±»å‹ï¼š{img.dtype}")

    # åˆå§‹åŒ–éšæœºç§å­
    set_seed(args.seed)
    # è®¾ç½®æ¨ç†é»˜è®¤å‚æ•°
    set_default_infer(args)

    # åˆ›å»ºç½‘ç»œæ¨¡å‹
    network = create_model(
        model_name=args.network.model_name,      # æ¨¡å‹åç§°
        model_cfg=args.network,                  # æ¨¡å‹é…ç½®
        num_classes=args.data.nc,                # ç±»åˆ«æ•°é‡
        sync_bn=False,                           # æ˜¯å¦åŒæ­¥ BatchNormï¼ˆæ¨ç†ä¸­é€šå¸¸è®¾ä¸º Falseï¼‰
        checkpoint_path=args.weight,             # æ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„
    )
    # è®¾ç½®æ¨¡å‹ä¸ºæ¨ç†æ¨¡å¼ï¼ˆéè®­ç»ƒæ¨¡å¼ï¼‰
    network.set_train(False)
    # å¯ç”¨è‡ªåŠ¨æ··åˆç²¾åº¦ï¼ˆå¦‚æœè®¾ç½®äº† AMP çº§åˆ«ï¼‰
    ms.amp.auto_mixed_precision(network, amp_level=args.ms_amp_level)

    # å¢å¼ºå‹è¾“å…¥å¤„ç†ï¼ˆæ”¯æŒå†…å­˜å¸§å’Œæ–‡ä»¶è·¯å¾„ï¼‰
    if frame is not None:
        img = frame.copy()
        logger.debug(f'[è¾“å…¥éªŒè¯] å†…å­˜å¸§ä¿¡æ¯ ç±»å‹ï¼š{img.dtype} å½¢çŠ¶ï¼š{img.shape} å‡å€¼ï¼š{np.mean(img):.2f}')
    elif isinstance(args.image_path, np.ndarray):
        if args.image_path.dtype != np.uint8 or args.image_path.ndim != 3:
            raise ValueError("è§†é¢‘å¸§æ ¼å¼å¿…é¡»ä¸ºuint8ç±»å‹çš„3ç»´numpyæ•°ç»„ï¼ˆHWC-BGRæ ¼å¼ï¼‰")
        img = args.image_path.copy()
    else:
        if not os.path.exists(args.image_path):
            raise ValueError(f"Detect: input image file not available.")  # å›¾åƒè·¯å¾„æ— æ•ˆæ—¶æŠ›å‡ºå¼‚å¸¸
        img = cv2.imread(args.image_path)

    # åˆ¤æ–­æ˜¯å¦ä¸º COCO æ•°æ®é›†
    is_coco_dataset = "coco" in args.data.dataset_name

    # æ ¹æ®ä»»åŠ¡ç±»å‹è¿›è¡Œæ¨ç†ï¼ˆä¿®æ”¹draw_resultè°ƒç”¨æ–¹å¼ï¼‰
    if args.task == "detect":
        result_dict = detect(
            network=network,
            img=img,
            conf_thres=args.conf_thres,
            iou_thres=args.iou_thres,
            conf_free=args.conf_free,
            exec_nms=args.exec_nms,
            nms_time_limit=args.nms_time_limit,
            img_size=args.img_size,
            stride=max(max(args.network.stride), 32),
            num_class=args.data.nc,
            is_coco_dataset=is_coco_dataset,
        )
        # ä¿®æ”¹draw_resultè°ƒç”¨æ–¹å¼
        plot_img = draw_result(
            img,  # ç›´æ¥ä½¿ç”¨å›¾åƒæ•°æ®è€Œä¸æ˜¯è·¯å¾„
            result_dict, 
            args.data.names,
            is_coco_dataset=is_coco_dataset
        )
        # åœ¨detectä»»åŠ¡çš„ç»“æœä¿å­˜éƒ¨åˆ†æ·»åŠ ç›®å½•åˆ›å»º
        if args.save_result:
            save_dir = os.path.join(args.save_dir, "detect_results")
            os.makedirs(save_dir, exist_ok=True)
            save_path = os.path.join(save_dir, f"result_{int(time.time())}.jpg")
            
            if plot_img is not None:
                cv2.imwrite(save_path, plot_img)
            else:
                logger.error("Failed to save result: empty output image")

    elif args.task == "segment":
        result_dict = segment(
            network=network,
            img=img,
            conf_thres=args.conf_thres,
            iou_thres=args.iou_thres,
            conf_free=args.conf_free,
            nms_time_limit=args.nms_time_limit,
            img_size=args.img_size,
            stride=max(max(args.network.stride), 32),
            num_class=args.data.nc,
            is_coco_dataset=is_coco_dataset,
        )

        # ä¿®å¤åˆ†å‰²ä»»åŠ¡ç»˜å›¾å‚æ•°
        plot_img = draw_result(


            img,  # æ”¹ä¸ºç›´æ¥ä½¿ç”¨å›¾åƒæ•°æ®
            result_dict,
            args.data.names,
            is_coco_dataset=is_coco_dataset
        )
        if args.save_result:
            save_path = os.path.join(args.save_dir, "segment_results", "result.jpg")
            cv2.imwrite(save_path, plot_img)
            logger.info(f'åˆ†å‰²ç»“æœå·²ä¿å­˜è‡³ï¼š{save_path}')

    # è¿”å›å¤„ç†åçš„å›¾åƒï¼ˆä¿æŒBGRæ ¼å¼ï¼‰
    return plot_img



if __name__ == "__main__":
    # è·å–æ¨ç†å‚æ•°è§£æå™¨
    parser = get_parser_infer()
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parse_args(parser)
    # æ‰§è¡Œæ¨ç†
    infer(args)
version: '3.8'

services:
  # 智能推理服务 - 自动GPU/CPU检测 (推荐)
  inference-server:
    build:
      context: ..
      dockerfile: docker/Dockerfile
      args:
        BASE_IMAGE: cpu-base  # 默认CPU基础镜像
    container_name: yolo-inference-smart
    volumes:
      - ../weights:/app/weights:ro
      - ../test_images:/app/test_images:ro
      - ../outputs:/app/outputs
      - ../configs:/app/configs:ro
    environment:
      - PYTHONUNBUFFERED=1
      - AUTO_DEVICE_SELECTION=true
      - DEVICE_DETECTION_MODE=smart
    ports:
      - "8000:8000"
    restart: unless-stopped
    networks:
      - inference-net

  # GPU强制模式 - 仅在需要强制GPU时使用
  inference-server-gpu:
    build:
      context: ..
      dockerfile: docker/Dockerfile
      args:
        BASE_IMAGE: gpu-base  # 强制GPU基础镜像
    container_name: yolo-inference-gpu
    volumes:
      - ../weights:/app/weights:ro
      - ../test_images:/app/test_images:ro
      - ../outputs:/app/outputs
      - ../configs:/app/configs:ro
    environment:
      - PYTHONUNBUFFERED=1
      - DEVICE_TARGET=GPU
      - CUDA_VISIBLE_DEVICES=0
    ports:
      - "8001:8000"
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    networks:
      - inference-net
    profiles:
      - gpu-explicit

  # CPU专用模式 - 强制CPU，忽略GPU
  inference-server-cpu:
    build:
      context: ..
      dockerfile: docker/Dockerfile
      args:
        BASE_IMAGE: cpu-base  # 强制CPU基础镜像
    container_name: yolo-inference-cpu
    volumes:
      - ../weights:/app/weights:ro
      - ../test_images:/app/test_images:ro
      - ../outputs:/app/outputs
      - ../configs:/app/configs:ro
    environment:
      - PYTHONUNBUFFERED=1
      - DEVICE_TARGET=CPU
    ports:
      - "8002:8000"
    restart: unless-stopped
    networks:
      - inference-net
    profiles:
      - cpu-only

networks:
  inference-net:
    driver: bridge
